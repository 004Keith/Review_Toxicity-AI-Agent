# AI Agent for Toxicity Detection in Logs

This project leverages a Hugging Face transformers zero-shot classifier to detect toxic or profane language in log data.

## 🚀 Features

- Zero-shot classification with Hugging Face transformers
- Profanity and toxicity detection in logs
- Customizable with Kaggle datasets via the `datasets` library

## 📁 Files

- `ai_agent_toxicity_detection.ipynb`: Main notebook with data loading, preprocessing, model inference, and evaluations.
- `requirements.txt`: Python dependencies.

## 🧪 Setup

```bash
git clone https://github.com/YOUR-USERNAME/ai-agent-toxicity
cd ai-agent-toxicity
pip install -r requirements.txt
jupyter notebook ai_agent_toxicity_detection.ipynb
```

## 🧠 Dependencies

- transformers
- datasets
- pandas
- torch

## 🛠 Future Enhancements

- Fine-tune a local transformer model for higher accuracy  
- Integrate into a real-time log monitoring pipeline  
- Expand to cover additional threat categories

## 🧑‍💻 Author

- Built as part of an AI & Security exploration project.
- Keith Warren Mathias - https://github.com/004Keith
- Prathvi G Shetty - https://github.com/BlunderingProgrammmer
  

## 📜 License

MIT License
